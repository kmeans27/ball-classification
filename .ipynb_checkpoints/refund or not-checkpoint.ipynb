{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88af6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0452efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "num_classes = 30\n",
    "epochs = 10\n",
    "refund_classes = [1, 12, 23]  # Classes allowed for refund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad48bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2904 images belonging to 30 classes.\n",
      "Found 711 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    ")\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    directory=\"balls\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    directory=\"balls\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd5591c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 89s 916ms/step - loss: 1.1056 - accuracy: 0.7145 - val_loss: 15.5632 - val_accuracy: 0.1758\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 83s 914ms/step - loss: 0.6289 - accuracy: 0.8340 - val_loss: 18.7917 - val_accuracy: 0.1083\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 83s 914ms/step - loss: 0.4846 - accuracy: 0.8685 - val_loss: 16.6174 - val_accuracy: 0.1392\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 83s 909ms/step - loss: 0.3127 - accuracy: 0.9146 - val_loss: 25.0091 - val_accuracy: 0.0577\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 82s 900ms/step - loss: 0.3547 - accuracy: 0.9118 - val_loss: 14.3872 - val_accuracy: 0.1224\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 82s 898ms/step - loss: 0.2498 - accuracy: 0.9335 - val_loss: 18.5452 - val_accuracy: 0.1111\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 82s 898ms/step - loss: 0.2199 - accuracy: 0.9397 - val_loss: 15.4234 - val_accuracy: 0.1674\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 82s 900ms/step - loss: 0.2332 - accuracy: 0.9377 - val_loss: 21.3289 - val_accuracy: 0.0788\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 83s 911ms/step - loss: 0.2490 - accuracy: 0.9384 - val_loss: 12.1542 - val_accuracy: 0.2208\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 83s 909ms/step - loss: 0.2144 - accuracy: 0.9418 - val_loss: 12.8819 - val_accuracy: 0.1350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f3fc85a790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and train the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(img_size[0], img_size[1], 3)),\n",
    "        tf.keras.applications.MobileNetV2(\n",
    "            include_top=False, weights=\"imagenet\", input_tensor=None, pooling=\"avg\"\n",
    "        ),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f891a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make predictions\n",
    "def predict_class(image_path):\n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size=img_size)\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = predictions[0].argmax() + 1  # Add 1 to convert from 0-indexed to 1-indexed\n",
    "\n",
    "    if predicted_class in refund_classes:\n",
    "        return \"refund\"\n",
    "    else:\n",
    "        return \"declined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f691f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 352ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'declined'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class(\"1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f6dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
